---
title: "Antibodies - Testing classifier"
teaching: 10
exercises: 2
---

:::::::::::::::::::::::::::::::::::::: questions 


- How may we check for overfitting in a trained machine learning classifier?

- How may we pick the most relevant data points that are related to the class of a sample?


::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives


- Check for overfitted data by testing with a totally naive dataset


::::::::::::::::::::::::::::::::::::::::::::::::


## Testing our Classifiers on a Naïve Dataset 

We can also take a totally naïve dataset that the model has not been exposed to. This is a measure that checks for overfitting. If we see that there is poor performance on this naïve "held back" dataset, then it could suggest overfitting to the training data. Using 20 Human and 20 mouse paired sequences from OAS, which were not used to train our models, it is possible to generate their encodings, and pass them through the optimised model, in order to test it.  In this case, we will use only the top-performing models: `ADABoost` and `GuassianNB`.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::knit_child("1-antibodies.Rmd")
library(reticulate)
use_python("/Users/sabaferdous/envL2D/bin/python3")
```
```{python, include=FALSE}
import sys
import pandas as pd
from pandas import read_csv
sys.path.append('../src/')
sys.path.append('')
from propythia.sequence import ReadSequence
sequence=ReadSequence()
from propythia.descriptors import Descriptor

```

```{python, include=FALSE}
from sklearn.utils import check_random_state, shuffle
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import StandardScaler
import numpy as np
from numpy import pi, linspace, cos, sin, append, ones, zeros, hstack, vstack, intp
from numpy import mgrid, linspace, c_, arange, mean, array
from numpy.random import uniform, seed

```

### **Machine Learning Models**
```{python, include=FALSE}
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN
from sklearn.cluster import SpectralClustering
from sklearn.cluster import AffinityPropagation
```

### **Plotting Results**
```{python, include=FALSE}
import matplotlib.pyplot as plt
from matplotlib.ticker import LinearLocator, FormatStrFormatter
from mpl_toolkits import mplot3d
from matplotlib.pyplot import subplots, axes, scatter, xticks
from matplotlib.colors import ListedColormap
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics.cluster import adjusted_rand_score
from sklearn import metrics
from sklearn.metrics import matthews_corrcoef
```

### **Model Optimisation**
```{python, include=FALSE}
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
```

```{python, include=FALSE}
## Propythia Command to get encodings
def get_descriptors(protein):
    encodings= protein.adaptable([3,4,5,6,7,8,9,10,11,12,13,14,17,18,19,20,21])
    return(encodings)
```

```{python, include=FALSE}
def Get_dataset(fasta):
    VH_sequences = []
    VL_sequences = []
    with open(fasta, "r") as f:
        for line in f:
            if line[0] == ">":
                if "_VH" in line:
                    sequence_to_add = f.readline().strip()
                    VH_sequences.append(sequence_to_add)
                elif "_VL" in line:
                    sequence_to_add = f.readline().strip()
                    VL_sequences.append(sequence_to_add)

    print(len(VH_sequences),len(VL_sequences))
    if len(VH_sequences) == len(VL_sequences):
        VH_dataframe = pd.DataFrame()
        VL_dataframe = pd.DataFrame()
        for i in range(len(VH_sequences)):
            ps_string=sequence.read_protein_sequence(VH_sequences[i])
            protein = Descriptor(ps_string)
            descriptors = get_descriptors(protein)
            VH_dataframe = VH_dataframe.append(descriptors, ignore_index=True)
        print("VH_data", VH_dataframe.shape)
        for i in range(len(VL_sequences)):
            ps_string=sequence.read_protein_sequence(VL_sequences[i])
            protein = Descriptor(ps_string)
            descriptors = get_descriptors(protein)
            VL_dataframe = VL_dataframe.append(descriptors, ignore_index=True)
        print("VL_data", VL_dataframe.shape)
# Now we join these two dataframes together so that each
# sample now has information about its VH and VL sequence.
    VH_dataframe_suffix = VH_dataframe.add_suffix('_VH')
    VL_dataframe_suffix = VL_dataframe.add_suffix('_VL')
    joined_dataframe_VH_VL = VH_dataframe_suffix.join(VL_dataframe_suffix)
    return(joined_dataframe_VH_VL)
```

```{python, include=FALSE}
joined_dataframe_VH_VL = read_csv("data/HumanMouseOAS_VH_VL_paired_data.faa_Full_descriptors.csv", header = 0)

joined_dataframe_VH_VL
```

```{python, include=FALSE}
RANDOM_SEED = 0
# Prepare training data and labels
labels1 = 1000*[1] # Human antibodies will be class 1
labels2 = 1000*[0] # Mouse antibodies will be class 0
labels = labels1+labels2
y=labels
print(len(y))

#Mouse ==1, Human == 0

dataset = joined_dataframe_VH_VL
dataset=dataset.loc[:, dataset.columns != 'Unnamed: 0'] # Removed the column called 'Unnamed'
print(dataset.shape) # Just to check that you have an equal number of labels to the number of samples
```

```{python, include=FALSE}
X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=.3, random_state=RANDOM_SEED, shuffle=True)

num_rows, num_cols = dataset.shape

print("Training set size: ", X_train.shape, "       Test set size: ", X_test.shape)
```


```{python, results = "hold"}
##Get Encodings for the Naïve Dataset###
naive_fasta = 'data/Naive_dataset.faa.txt'
naive_dataset = Get_dataset(naive_fasta)
naive_labels1 = 20*[1]
naive_labels2 = 20*[0]
naive_labels = naive_labels1+naive_labels2
naive_y=naive_labels
```

We should select high performing classifiers to test this naive dataset. We select the `ADABoost` and our improved `RFC` predictors to try this.

```{python, include=FALSE}
n=2
RANDOM_SEED=42
classifiers = {
    'Guassian':GaussianMixture(n_components=n),
    'KMeans': KMeans(n_clusters=n) ,
    'KNeighbours': KNeighborsClassifier(2),
    'SVC':SVC(kernel="linear", C=0.025),
   'SVC2': SVC(gamma=2, C=1),
    'DecisionTree': DecisionTreeClassifier(max_depth=5),
    'RFC': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    'MLPC': MLPClassifier(alpha=1, max_iter=1000),
    'ADABoost':AdaBoostClassifier(),
    'GaussianNB': GaussianNB(),
    'QDA':QuadraticDiscriminantAnalysis(),
}


```
```{python, include=FALSE}
##GridsearchCV of RFC Model####

param_grid = {
    'bootstrap': [True],
    'max_depth': [80, 90, 100, 110],
    'max_features': [2, 3],
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100, 200, 300, 1000]
}
# Create a based model
rf = RandomForestClassifier()
# Instantiate the grid search model
rf_grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, 
                          refit = True, cv = 3, n_jobs = -1, verbose = 2)
rf_grid_search.fit(X_train, y_train)
```

```{python, results="hold"}
###Predict the Classes of Naïve Datasets Using or Previously Fitted ADABoost and GRIDSEARCHCV RFC Models and Plot Confusion Matrix##

clf = classifiers.get('ADABoost')
clf.fit(X_train, y_train)
y_predict1 = clf.predict(naive_dataset)
scoring = matthews_corrcoef(naive_y, y_predict1)

cf_matrix1 = confusion_matrix(naive_y, y_predict1)
ax1 = sns.heatmap(cf_matrix1, annot=True, cmap='summer')
title = str("ADABoost_Naive_dataset_"+str(scoring))
ax1.set_title(title);
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Actual Values ');
plt.show()
# 
naive_labels = naive_labels1+naive_labels2
naive_y=naive_labels
clf = rf_grid_search
clf.fit(X_train, y_train)

y_predict1 = clf.predict(naive_dataset)
scoring = matthews_corrcoef(naive_y, y_predict1)
# scores.append(scoring)     
cf_matrix1 = confusion_matrix(naive_y, y_predict1)
ax1 = sns.heatmap(cf_matrix1, annot=True, cmap='summer')
title = str("RFC_gridsearch_Naive_dataset_"+str(scoring))
ax1.set_title(title);
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Actual Values ');
plt.show()

naive_labels = naive_labels1+naive_labels2
naive_y=naive_labels
clf = classifiers.get('KMeans')
clf.fit(X_train, y_train)
y_predict1 = clf.predict(naive_dataset)
scoring = matthews_corrcoef(naive_y, y_predict1)
     
cf_matrix1 = confusion_matrix(naive_y, y_predict1)
ax1 = sns.heatmap(cf_matrix1, annot=True, cmap='summer')
title = str("KMeans_Naive_dataset_"+str(scoring))
ax1.set_title(title);
ax1.set_xlabel('Predicted Values')
ax1.set_ylabel('Actual Values ');
plt.show()
```

It seems even GridSearchCV has not improved the RFC to the extent of the ADABoost, but it still shows good overall performance! As expected, we don't see very good performance with KMeans as it has mostly thought that all antibodies fit in Class 0 (Human).

## Dimensionality Reduction

As an additional task, we can try dimensionality reduction in the event that it might improve the performance of poorer predictors. Principal Component Analysis (PCA) is commonly applied in machine learning as a pre-processing step when dealing with data that contains multiple data points per sample. This increases interpretability of our data, and also allows us to plot it, visually. In short, it works to identify data points that can be grouped together and represented in a vector (principal components) to explain the variability seen in the data. Usually, they are ordered in reverse of how much variability they can explain (e.g. PC1 would explain the most variability, PCn would explain the least). 

We can then apply PCA to our dataset, and see if this changes the performance of our predictors.

```{python, results="hold"}
##Perform PCA 
nComp = 50 # Number of PCs to be returned

threshold = 0.999999

EncodingPCA = PCA(n_components=nComp, whiten=True)
EncodingPCA = EncodingPCA.fit(dataset)

cumExpVar = np.cumsum(EncodingPCA.explained_variance_ratio_)
keepPC = [pc for pc in range(nComp) if cumExpVar[pc]>=threshold][0]

NewEncodingPCA = EncodingPCA.transform(dataset)[:,range(keepPC)]
print(NewEncodingPCA.shape)
```

```{python}
##Train/Test Split##
X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(NewEncodingPCA, y, test_size=.3, random_state=RANDOM_SEED, shuffle=True)
num_rows, num_cols = dataset.shape
print("Training set size: ", X_train.shape, "       Test set size: ", X_test.shape)

```

```{python}
##Loop through classifiers and obtain MCC values of new datasets##
scores_PCA = []
for i in classifiers:
    clf_1 = classifiers.get(i)
    clf_1.fit(X_train_PCA,y_train_PCA)
    y_predict1 = clf_1.predict(X_test_PCA)
    scoring = matthews_corrcoef(y_test_PCA, y_predict1)
    scores_PCA.append(scoring)
    plt.show()
```

```{python, echo=FALSE, include=FALSE}
##Plot Score of Each Classifier Comparing Dataset with PCA and without PCA##
import numpy as np 
import matplotlib.pyplot as plt 
labels = list(classifiers.keys())
aranged = np.arange(len(classifiers)) 
width = 1/3

fig, ax = plt.subplots(figsize=(15,8))

bar1 = plt.bar(aranged, scores, width,label = 'No PCA')
bar2 = plt.bar(aranged+width, scores_PCA , width,label = 'PCA')
plt.suptitle('Performance of Machine Learning Classifiers Against Mouse and Human Antibodies with and Without PCA', fontsize=20)
ax.set_ylabel('MCC')
ax.set_xticks(aranged, labels, rotation = 90)
ax.legend()


plt.legend()
plt.show()
```
We see that some classifiers improve performance (SVC, MLPC,QDA) with the PCA but this is not always the case (Decision Tree, RFC, ADABoost).

```{python, echo=FALSE, include=FALSE}
##Visualising Data Plot##
fig, ax = plt.subplots(ncols=3, nrows=2, figsize=(25, 15))
plt.suptitle('PCA of Mouse Vs Human Encodings (Mouse = Purple, Human = Blue)', fontsize=20)

ax[0, 0].scatter(NewEncodingPCA[:,0], NewEncodingPCA[:,1], c=y, cmap='cool');
ax[0, 0].set_xlabel('PC1', fontsize=14); ax[0, 0].set_xlim([-2.5,2.5]);
ax[0, 0].set_ylabel('PC2', fontsize=14); ax[0, 0].set_ylim([-2.5,2.5]);


ax[0, 1].scatter(NewEncodingPCA[:,0], NewEncodingPCA[:,2], c=y, cmap='cool');
ax[0, 1].set_xlabel('PC1', fontsize=14); ax[0, 1].set_xlim([-2.5,2.5]);
ax[0, 1].set_ylabel('PC3', fontsize=14); ax[0, 1].set_ylim([-2.5,2.5]);


ax[0, 2].scatter(NewEncodingPCA[:,0], NewEncodingPCA[:,3], c=y, cmap='cool');
ax[0, 2].set_xlabel('PC1', fontsize=14); ax[0, 2].set_xlim([-2.5,2.5]);
ax[0, 2].set_ylabel('PC4', fontsize=14); ax[0, 2].set_ylim([-2.5,2.5]);


ax[1, 0].scatter(NewEncodingPCA[:,1], NewEncodingPCA[:,2], c=y, cmap='cool');
ax[1, 0].set_xlabel('PC2', fontsize=14); ax[1, 0].set_xlim([-2.5,2.5]);
ax[1, 0].set_ylabel('PC3', fontsize=14); ax[1, 0].set_ylim([-2.5,2.5]);


ax[1, 1].scatter(NewEncodingPCA[:,1], NewEncodingPCA[:,3], c=y, cmap='cool');
ax[1, 1].set_xlabel('PC2', fontsize=14); ax[1, 1].set_xlim([-2.5,2.5]);
ax[1, 1].set_ylabel('PC4', fontsize=14); ax[1, 1].set_ylim([-2.5,2.5]);


ax[1, 2].scatter(NewEncodingPCA[:,3], NewEncodingPCA[:,2], c=y, cmap='cool');
ax[1, 2].set_xlabel('PC4', fontsize=14); ax[1, 2].set_xlim([-2.5,2.5]);
ax[1, 2].set_ylabel('PC3', fontsize=14); ax[1, 2].set_ylim([-2.5,2.5]);

plt.show()
```

We can see here that the graphs showing PC1 against PC3 and PC2 against PC3 show some the best separation between human and mouse antibodies. We can use this to support the trustworthiness of our dimensionality reduction technique.

::::::::::::::::::::::::::::::: challenge 

## Do it Yourself

We can use other methods of reducing the dimensionality of the dataset. F-regression is a technique that selects the n most relevant features to the target variable. It can be performed on the dataset like so:

```
from sklearn.feature_selection import SelectKBest`
from sklearn.feature_selection import f_regression
n = 100
X_NUMPY, Y_NUMPY = X.to_numpy(),y.to_numpy()
fs = SelectKBest(score_func=f_regression, k=n)
X_selected = fs.fit_transform(X_NUMPY, Y_NUMPY)
```

Experiment with the n this method of dimensionality reduction on your data and see how the results compare to the Principle Component Analysis?
	
	
::::::::::::::::: solution
	
## DIY ANSWER


:::::::::::::::::

::::::::::::::::::::::::::::::: 

::::::::::::::::::::::::::::::::::::: keypoints 

- Check the performance of your model with a "held back" dataset which was not included in the training set.

::::::::::::::::::::::::::::::::::::::::::::::::


[r-markdown]: https://rmarkdown.rstudio.com/
